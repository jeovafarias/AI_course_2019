{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Training, Testing and Loss\n",
    "Hopefully, you have your perceptron working now :). With it, we'll put in practice some of the concepts we learnt on class! So, first of all, bring all the important code from the last notebook (you'll need ``add_bias()``, ``perceptron``, ``preprocess_data()`` and ``plot_data()``). I'm also giving you a function ``fit_line_dataset(x, y, data)`` that \"crops\" the line in your ``plot_data()`` and makes your figure nicer :). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def fit_line_dataset(x, y, data):\n",
    "    line = np.stack((x, y), axis=1)\n",
    "    flags = np.all(np.logical_and(line < np.max(data, axis=0)[0:2], line > np.min(data, axis=0)[0:2]), axis=1)\n",
    "    line = line[flags, :]\n",
    "    new_x = line[:, 0]\n",
    "    new_y = line[:, 1]\n",
    "    # Plot these returns in your code \"plot_data(data, w)\"\n",
    "    return new_x, new_y\n",
    "\n",
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Tracking the Perceptron loss\n",
    "Before anything, let's first count how many mistakes the perceptron makes in each epoch (the loss of that epoch), keep track of it over all the epochs in a vector and plot it at the end. We will be using this function only o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_with_loss(X, classes):\n",
    "    # Your code goes here\n",
    "    return w, loss\n",
    "\n",
    "data = np.loadtxt('data/data.txt')\n",
    "\n",
    "X, classes = preprocess_data(data)\n",
    "w, loss = perceptron_with_loss(X, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Training and Testing dataset\n",
    "So, you were given a dataset and you came up with some classifier (the \"Perceptron\" Classifier). How can we measure how good it is? Well, we can use a **testing** dataset to do it. So, you find the best $w$ with a given dataset (the **training** dataset) and then test $w$ with the testing dataset. Simply, right?\n",
    "\n",
    "But I just gave *one* dataset to you last time (``data.txt``)! Where are the training and testing dataset? Well, I guess the only option is to get them ``data.txt``. So, I'll give you a number (``ratio``) that signifies the size of the training set compared to the total size of ``data.txt``. In other words, you'll split the data in two and from them you'll get the training  and testing datasets. Would you be able to code it up? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_datasets(data, ratio):\n",
    "    assert ratio > 0 and ratio < 1\n",
    "    \n",
    "    # Your code goes here\n",
    "    \n",
    "    return X_train, X_test, classes_train, classes_test\n",
    "\n",
    "data = np.loadtxt('data/data.txt')\n",
    "ratio = .7\n",
    "X_train, X_test, classes_train, classes_test = get_datasets(data, ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Testing the Perceptron\n",
    "Now, let's test how good of a job the perceptron is doing. So, the it will output a variable $w$. How can you use it to classify one datapoint, say $x = [1, x_1, x_2]$? Create a function ``classify(x, w)`` that does it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(x, w):\n",
    "    # Your code goes here\n",
    "    return cla\n",
    "    \n",
    "x = np.array([1, 1, 2])\n",
    "w = np.array([3, 4, 2])\n",
    "print(classify(w, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, how about computing $w$ from the training set (``X_train`` and ``classes_train``) and then classify all the points in ``X_test``? To do so, store the resulting classes in a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_all_points(X, w):\n",
    "    # Your code goes here\n",
    "    \n",
    "    return classification\n",
    "\n",
    "data = np.loadtxt('data/data.txt')\n",
    "ratio = .7\n",
    "X_train, X_test, classes_train, classes_test = get_datasets(data, ratio)\n",
    "\n",
    "w = perceptron(X_train, classes_train)\n",
    "classes = classify_all_points(X_test, w)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now plot the training and testing datasets along with the predicted decision boundary using the training data. Do do so, remember the function you had to plot the data and the separator (that line that you computed from $w$)? Now, make a function that receives the output of ``get_datasets()`` (``X_train``, ``X_test``, ``classes_train`` and ``classes_test``) and scatter the all these points in a way that the training data is much less opaque than the testing data (use this [link](https://matplotlib.org/3.1.0/api/_as_gen/matplotlib.pyplot.scatter.html) as a reference)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_and_test_data(X_train, X_test, classes_train, classes_test, w):\n",
    "    # Your code goes here\n",
    "    plt.show()\n",
    "\n",
    "data, ratio = np.loadtxt('data/data.txt'), .7\n",
    "X_train, X_test, classes_train, classes_test = get_datasets(data, ratio)\n",
    "w = perceptron(X_train, classes_train)\n",
    "\n",
    "plot_training_and_test_data(X_train, X_test, classes_train, classes_test, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can you say about the previous result?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Loss and accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! Now, we've got a classification! Well, is it a good classification? We have the true classification in ``classes_test``. What is the zero-one loss value of that classification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(classification, classes_test):\n",
    "    return # Your code goes here\n",
    "\n",
    "ratio = .7\n",
    "data = np.loadtxt('data/data.txt')\n",
    "X_train, X_test, classes_train, classes_test = get_datasets(data, ratio)\n",
    "\n",
    "w = perceptron(X_train, classes_train)\n",
    "classes_perceptron = classify_all_points(X_test, w)\n",
    "\n",
    "print(loss(classes_perceptron, classes_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we are here, what would be the *accuracy* of our classification? How would you define accuracy? How would you compute it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(classification, classes_test):\n",
    "    return # Your code goes here\n",
    "\n",
    "ratio = .7\n",
    "data = np.loadtxt('data/data.txt')\n",
    "X_train, X_test, classes_train, classes_test = get_datasets(data, ratio)\n",
    "\n",
    "w = perceptron(X_train, classes_train)\n",
    "classes_perceptron = classify_all_points(X_test, w)\n",
    "\n",
    "print(accuracy(classes_perceptron, classes_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it for today!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
