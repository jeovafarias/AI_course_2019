{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E10.1 Showing the images and their predictions\n",
    "So, use the next code block to bring everything you needed from Keras to compute the predictions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, do the following: create a function ``plot_image_n_prediction(image, prediction)`` that receives an image an the predicted percentage vector of that image. It'll show them with ``imshow()`` and set their title with the predicted number (class) and the prediction \"conviction\" of the classifier has about its prediction. Ex.: The title could be \"Number 1 (99.55%)\". Show three images in this way using subplots. Hint.: use ``np.round(100 * something, decimals=2)`` to make the percentages look nice :)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [25, 5]\n",
    "\n",
    "def plot_image_n_prediction(image, prediction):\n",
    "    # Your code goes here   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E10.2 Training for more epochs\n",
    "Now, redo the previous experiments with more epochs (you choose the number). What happens to the accuracy and the final loss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E10.3 Training with different activation functions\n",
    "We used the sigmoid in the initial code. How about using the ReLU (Rectified Linear Unit). This is what is most commonly used nowadays. Let's also try the Hyperbolic Tangent (tanh). As a side info, here's how the look like:\n",
    "![a](images/Relu_tanh.png)\n",
    "So, report the results of ``activation=\"relu\"`` and ``activation=\"tanh\"`` for the same number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E10.4 Testing other optimizers\n",
    "We used Stochastic Gradient Descent (``SGD``) as the optimizer, simply because we have sorta studied it in class. In practice people use  [``\"Adam\"``](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam)as an optimizer. Run your initial code with this optimizer and report any difference. Check if for different number of epochs. Also, plot the same images and their predictions as in 10.1, but now with these new results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E10.5 Going Deeper\n",
    "What happens if you added more dense layers? Does the accuracy improve? So, keep the same initial set up we had and add 1, 2 and then 3 dense layers. What happens? Report the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E10.6 Using convolutions\n",
    "Now, let's try to implement the following model:\n",
    "![a](images/cnn.jpeg)\n",
    "It uses convolutions layers, followed by max pooling layers. In Keras, they are input to the model as:\n",
    "\n",
    "- ``Conv2D(num_filters, kernel_size, activation='relu')``: You can set the number of filters as you want. The correspond to the convolution filters we saw yesterday. Let's set it to 32 and then we can try 64. The kernel size is the size of the kernel (\"dah\") and we used (3, 3) as a reference. This means that the filters will be 3 x 3 matrices.\n",
    "- ``MaxPooling2D(pool_size)``: The ``pool_size`` we used yesterday and that is commonly used is ``(2, 2)``. \n",
    "\n",
    "Don't forget to have the ``Flatten`` layers and the ``Dense`` layers as before. Run this new code on ``epochs=5`` and use the ``SGD`` as an optimizer. Show some predictions/images and report the results.\n",
    "\n",
    "OBS.: These layers only accept color images as inputs, i.e., the inputs should be composed of 3 channels. The MNIST dataset has only graylevel images and therefore we need to find a way to \"pretend\" they are color images. We can do it by adding the next lines in your code after you loaded the train and test datasets:\n",
    "\n",
    "``train_images = np.expand_dims(train_images, axis=3)``\n",
    "\n",
    "``test_images = np.expand_dims(test_images, axis=3)``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E10.7 Check you this visualization!\n",
    "So, someone very smart kinda implemented what you just coded and posted this nice visialization about it. Check it out: http://scs.ryerson.ca/~aharley/vis/conv/flat.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E10.8 Fashion MNIST\n",
    "Ok, handwritten digits are actually kinda boring. How about a more *realistic* dataset? So this is Fashion-MNIST:\n",
    "![a](images/fashion-mnist-sprite.png)\n",
    "As you noticed, it is a bunch individual articles of clothing at low resolution (28 by 28 pixels). It contains 70,000 grayscale images in 10 categories, just like MNIST. You can load it with:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels are still an array of integers, ranging from 0 to 9, but now they correspond to the *class* of clothing the image represents:\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Label</th>\n",
    "    <th>Class</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>0</td>\n",
    "    <td>T-shirt/top</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1</td>\n",
    "    <td>Trouser</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>2</td>\n",
    "    <td>Pullover</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>3</td>\n",
    "    <td>Dress</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>4</td>\n",
    "    <td>Coat</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>5</td>\n",
    "    <td>Sandal</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>6</td>\n",
    "    <td>Shirt</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>7</td>\n",
    "    <td>Sneaker</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>8</td>\n",
    "    <td>Bag</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>9</td>\n",
    "    <td>Ankle boot</td>\n",
    "  </tr>\n",
    "</table> \n",
    "Each image is mapped to a single label. Since the *class names* are not included with the dataset, store them here to use later when plotting the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task now is to repeat the same things we did before for MNIST with the Fashion-MNIST data. Also, make a new ``plot_image_n_prediction`` that explicitly outputs the predicted class name using the list ``class_names`` above. Try to find a set up (num. of  layers, optimizer, activation function, etc) that makes the highest accuracy in the class! Report the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
